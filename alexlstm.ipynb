{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import pipeline\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Laden der bereinigten CSV-Datei\n",
    "df = pd.read_csv(\"df.csv\")\n",
    "\n",
    "# Schritt 1: Sentimentanalyse hinzufügen\n",
    "print(\"Starte Sentimentanalyse...\")\n",
    "\n",
    "# Verwende Hugging Face's Transformers Pipeline für die Sentimentanalyse\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "# Sicherstellen, dass alle Einträge Strings sind\n",
    "df['Filtered_Content'] = df['Filtered_Content'].fillna(\"\").astype(str)\n",
    "\n",
    "# Funktion zur Berechnung des Sentiments\n",
    "def compute_sentiment(text):\n",
    "    if isinstance(text, str) and len(text) > 0:\n",
    "        result = sentiment_analyzer(text[:512])[0]  # Text auf 512 Zeichen begrenzen\n",
    "        return result['label'], result['score']\n",
    "    else:\n",
    "        return \"NEUTRAL\", 0.0  # Standardwerte für ungültige Einträge\n",
    "\n",
    "# Berechnung von Sentiment und Scores\n",
    "df['Sentiment'], df['Sentiment_Score'] = zip(*df['Filtered_Content'].apply(compute_sentiment))\n",
    "\n",
    "\n",
    "# Speichern der Ergebnisse in einer Datei\n",
    "df.to_csv(\"sentiment_results.csv\", index=False)\n",
    "print(\"Sentimentanalyse abgeschlossen und gespeichert.\")\n",
    "\n",
    "# Schritt 2: TF-IDF Vektorisierung\n",
    "print(\"Starte TF-IDF Vektorisierung...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Begrenze auf 1000 Features für bessere Performance\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['Filtered_Content'])\n",
    "y = df['NegoOutcomeLabel']\n",
    "\n",
    "# Speichern des TF-IDF-Vektorizers\n",
    "joblib.dump(tfidf_vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Schritt 3: Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Schritt 4: Training eines komplexeren Modells\n",
    "print(\"Starte Training eines RandomForest-Klassifikators...\")\n",
    "rf_classifier = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Modellergebnisse:\")\n",
    "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Speichern des Modells\n",
    "joblib.dump(rf_classifier, \"random_forest_model.pkl\")\n",
    "\n",
    "# Schritt 5: Speichern der Ergebnisse\n",
    "results = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"classification_report\": classification_report(y_test, y_pred, output_dict=True)\n",
    "}\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"model_results.csv\", index=False)\n",
    "\n",
    "print(\"Alle Ergebnisse gespeichert.\")\n",
    "\n",
    "# Dokumentation der Top-TFIDF-Features\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "important_features = sorted(zip(feature_importances, feature_names), reverse=True)[:50]\n",
    "important_features_df = pd.DataFrame(important_features, columns=[\"Importance\", \"Feature\"])\n",
    "important_features_df.to_csv(\"top_tfidf_features.csv\", index=False)\n",
    "\n",
    "print(\"Top TF-IDF Features gespeichert.\")\n",
    "\n",
    "# Schritt 6: Korrelation von Sentiment mit Erfolg\n",
    "print(\"Berechne Korrelation zwischen Sentiment und Erfolg...\")\n",
    "sentiment_success = df.groupby(['Sentiment', 'NegoOutcomeLabel']).size().unstack(fill_value=0)\n",
    "sentiment_success.to_csv(\"sentiment_success_correlation.csv\")\n",
    "\n",
    "print(\"Korrelationsergebnisse gespeichert.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
