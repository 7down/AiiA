{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ReceiverID    ActionType  NegoOutcome  \\\n",
      "0          32         Offer  FinalAccept   \n",
      "1          31  Counteroffer  FinalAccept   \n",
      "2          32  Counteroffer  FinalAccept   \n",
      "3          31  Counteroffer  FinalAccept   \n",
      "4          32      Question  FinalAccept   \n",
      "\n",
      "                                             Content  Length  \\\n",
      "0  hey chris great working together competition h...    1778   \n",
      "1  hey alex pleasure mine starters think importan...    1949   \n",
      "2  hey chris thank response glad hear agree date ...     693   \n",
      "3  hello alex think solid compromis settled willi...     452   \n",
      "4  dear chris glad hear willing accept terms come...    1349   \n",
      "\n",
      "   Word count of nego message  NegoOutcomeLabel  \\\n",
      "0                         309                 1   \n",
      "1                         337                 1   \n",
      "2                         123                 1   \n",
      "3                          77                 1   \n",
      "4                         249                 1   \n",
      "\n",
      "                                    Filtered_Content  \n",
      "0  working together competition hereby first prop...  \n",
      "1  mine starters think important acknowledge isa ...  \n",
      "2  response glad hear agree date conference accep...  \n",
      "3  solid compromis settled willing accept terms w...  \n",
      "4  hear willing accept terms come agreement sure ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('df.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 23:55:33.573868: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-24 23:55:34.167050: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-24 23:55:34.167093: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-24 23:55:34.167123: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-24 23:55:34.185868: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-24 23:55:40.365585: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ReceiverID    ActionType  NegoOutcome  \\\n",
      "0          32         Offer  FinalAccept   \n",
      "1          31  Counteroffer  FinalAccept   \n",
      "2          32  Counteroffer  FinalAccept   \n",
      "3          31  Counteroffer  FinalAccept   \n",
      "4          32      Question  FinalAccept   \n",
      "\n",
      "                                             Content  Length  \\\n",
      "0  hey chris great working together competition h...    1778   \n",
      "1  hey alex pleasure mine starters think importan...    1949   \n",
      "2  hey chris thank response glad hear agree date ...     693   \n",
      "3  hello alex think solid compromis settled willi...     452   \n",
      "4  dear chris glad hear willing accept terms come...    1349   \n",
      "\n",
      "   Word count of nego message  NegoOutcomeLabel  \\\n",
      "0                         309                 1   \n",
      "1                         337                 1   \n",
      "2                         123                 1   \n",
      "3                          77                 1   \n",
      "4                         249                 1   \n",
      "\n",
      "                                    Filtered_Content  \\\n",
      "0  working together competition hereby first prop...   \n",
      "1  mine starters think important acknowledge isa ...   \n",
      "2  response glad hear agree date conference accep...   \n",
      "3  solid compromis settled willing accept terms w...   \n",
      "4  hear willing accept terms come agreement sure ...   \n",
      "\n",
      "             Tokenized_Content  \\\n",
      "0  [input_ids, attention_mask]   \n",
      "1  [input_ids, attention_mask]   \n",
      "2  [input_ids, attention_mask]   \n",
      "3  [input_ids, attention_mask]   \n",
      "4  [input_ids, attention_mask]   \n",
      "\n",
      "                                          Embeddings  \n",
      "0  [-0.35223728, 0.15231456, 0.50895715, -0.10631...  \n",
      "1  [-0.322315, 0.19558503, 0.55482864, -0.1491403...  \n",
      "2  [-0.34745067, 0.24593507, 0.42270607, -0.05545...  \n",
      "3  [-0.1199348, 0.20919886, 0.40716514, 0.0667471...  \n",
      "4  [-0.33000934, 0.05643478, 0.48571908, -0.11051...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "import pickle\n",
    "# Load the DistilBERT tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize the text data\n",
    "def tokenize_text(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    return inputs\n",
    "\n",
    "# Apply tokenization to the 'Content' column\n",
    "df['Tokenized_Content'] = df['Content'].apply(tokenize_text)\n",
    "\n",
    "# Perform inference using the model\n",
    "def get_embeddings(tokenized_text):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized_text)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Apply the model to get embeddings for each tokenized text\n",
    "df['Embeddings'] = df['Tokenized_Content'].apply(get_embeddings)\n",
    "\n",
    "\n",
    "# Save the DataFrame to a pickle file\n",
    "with open('df_with_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file (without embeddings)\n",
    "df.drop(columns=['Tokenized_Content', 'Embeddings']).to_csv('df_with_embeddings.csv', index=False)\n",
    "\n",
    "# Display the DataFrame with embeddings\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7849223946784922\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.10      0.17       104\n",
      "           1       0.79      0.99      0.88       347\n",
      "\n",
      "    accuracy                           0.78       451\n",
      "   macro avg       0.78      0.54      0.52       451\n",
      "weighted avg       0.78      0.78      0.71       451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Lade die DataFrame mit Embeddings aus der Pickle-Datei\n",
    "with open('df_with_embeddings.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "# Zielvariable (Label) und Features definieren\n",
    "X = df['Embeddings'].tolist()  # Die BERT-Embeddings als Features\n",
    "y = df['NegoOutcomeLabel']     # Die Zielvariable für Erfolg (1) oder keinen Erfolg (0)\n",
    "\n",
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Trainiere ein Klassifikationsmodell (z. B. RandomForest)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Teste das Modell\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Ergebnisse auswerten\n",
    "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ergebnis enthält wichtige Metriken zur Bewertung des Modells, insbesondere zur Performance bei der Vorhersage der beiden Klassen (`0` und `1`). Hier ist eine Erklärung der verschiedenen Teile:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Model Accuracy: 0.79 (79%)**\n",
    "- **Bedeutung**: Das Modell liegt in 79% der Fälle richtig, wenn man alle Vorhersagen (Klasse `0` und `1`) berücksichtigt.\n",
    "- **Einschränkung**: Accuracy allein kann irreführend sein, insbesondere bei einem **unausgeglichenen Datensatz**, was hier der Fall ist (es gibt 347 Beispiele für Klasse `1` und nur 104 für Klasse `0`).\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Classification Report**\n",
    "Die wichtigsten Begriffe im Classification Report:\n",
    "\n",
    "#### Klasse `0` (kein Erfolg):\n",
    "- **Precision (1.00)**: Von allen Beispielen, die das Modell als `0` (kein Erfolg) klassifiziert hat, waren 100% tatsächlich `0`. Das Modell gibt also keine falschen Positiven für `0`.\n",
    "- **Recall (0.10)**: Von allen echten Beispielen der Klasse `0` erkennt das Modell nur 10%. Es übersieht also viele Fälle, in denen es sich tatsächlich um Klasse `0` handelt.\n",
    "- **F1-Score (0.18)**: Dies ist der harmonische Mittelwert von Precision und Recall. Da der Recall so niedrig ist, ist der F1-Score für Klasse `0` ebenfalls sehr niedrig.\n",
    "\n",
    "#### Klasse `1` (Erfolg):\n",
    "- **Precision (0.79)**: Von allen Beispielen, die als `1` (Erfolg) vorhergesagt wurden, waren 79% korrekt.\n",
    "- **Recall (1.00)**: Von allen echten Beispielen der Klasse `1` erkennt das Modell 100%. Es übersieht keine erfolgreichen Verhandlungen.\n",
    "- **F1-Score (0.88)**: Da sowohl Precision als auch Recall relativ hoch sind, ergibt sich ein guter F1-Score.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Durchschnittswerte**\n",
    "- **Macro Avg** (Durchschnitt der Metriken über alle Klassen, ungewichtet):\n",
    "  - **Precision (0.89)**: Der Durchschnitt der Precision über beide Klassen.\n",
    "  - **Recall (0.55)**: Der Durchschnitt der Recall-Werte. Der niedrige Wert für Klasse `0` zieht den Durchschnitt herunter.\n",
    "  - **F1-Score (0.53)**: Der Durchschnitt der F1-Scores über beide Klassen. Dies zeigt, dass das Modell für Klasse `0` schwach ist.\n",
    "  \n",
    "- **Weighted Avg** (Durchschnitt der Metriken, gewichtet nach der Anzahl der Beispiele pro Klasse):\n",
    "  - **Precision (0.84)**: Berücksichtigt, dass die Klasse `1` häufiger vorkommt.\n",
    "  - **Recall (0.79)**: Spiegelt die Gesamtaccuracy des Modells wider.\n",
    "  - **F1-Score (0.72)**: Ein gewichteter F1-Score.\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretation**\n",
    "1. **Starke Leistung für Klasse `1`** (Erfolg):\n",
    "   - Das Modell erkennt alle erfolgreichen Verhandlungen (Recall = 1.00) und macht nur wenige Fehler bei der Vorhersage dieser Klasse (Precision = 0.79).\n",
    "   - Dies ist hilfreich, wenn es wichtiger ist, Erfolge zuverlässig zu erkennen.\n",
    "\n",
    "2. **Schwache Leistung für Klasse `0`** (kein Erfolg):\n",
    "   - Das Modell hat große Schwierigkeiten, nicht-erfolgreiche Verhandlungen korrekt zu erkennen (Recall = 0.10). Es übersieht fast alle Fälle, in denen die Verhandlung kein Erfolg war.\n",
    "   - Dies liegt vermutlich daran, dass der Datensatz unausgeglichen ist (viel mehr Beispiele für Klasse `1`).\n",
    "\n",
    "3. **Unausgeglichener Datensatz**:\n",
    "   - Die Klasse `1` dominiert den Datensatz (347 vs. 104). Dies führt dazu, dass das Modell stark auf Klasse `1` optimiert ist und Klasse `0` vernachlässigt.\n",
    "\n",
    "---\n",
    "\n",
    "### **Verbesserungsmöglichkeiten**\n",
    "Um die Erkennung von Klasse `0` (kein Erfolg) zu verbessern:\n",
    "1. **Balanciere den Datensatz aus**:\n",
    "   - Verwende Techniken wie Oversampling (z. B. SMOTE) für die unterrepräsentierte Klasse `0` oder Downsampling für die überrepräsentierte Klasse `1`.\n",
    "\n",
    "2. **Klassengewicht anpassen**:\n",
    "   - Viele Modelle (z. B. Random Forest oder Logistic Regression) erlauben es, Gewichte für Klassen zu setzen. Dies hilft, das Ungleichgewicht zu kompensieren:\n",
    "     ```python\n",
    "     clf = RandomForestClassifier(class_weight={0: 2, 1: 1}, random_state=42)\n",
    "     ```\n",
    "\n",
    "3. **Andere Modelle ausprobieren**:\n",
    "   - Modelle wie Gradient Boosting (XGBoost, LightGBM) oder neuronale Netze könnten besser mit dem Ungleichgewicht umgehen.\n",
    "\n",
    "4. **Feature Engineering**:\n",
    "   - Zusätzliche Features wie die Länge der Nachricht oder spezifische Schlüsselwörter könnten helfen, die Unterscheidung zwischen `0` und `1` zu verbessern.\n",
    "\n",
    "---\n",
    "\n",
    "Möchtest du eine der Verbesserungsmöglichkeiten umsetzen? Ich kann dir helfen, beispielsweise eine Methode zur Datenbalance oder zur Anpassung der Klassengewichte einzubauen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after SMOTE: Counter({1: 1448, 0: 1448})\n",
      "Model Accuracy: 0.7827050997782705\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.29      0.38       104\n",
      "           1       0.81      0.93      0.87       347\n",
      "\n",
      "    accuracy                           0.78       451\n",
      "   macro avg       0.68      0.61      0.62       451\n",
      "weighted avg       0.75      0.78      0.76       451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE  # SMOTE für Oversampling\n",
    "\n",
    "# Lade die DataFrame mit Embeddings aus der Pickle-Datei\n",
    "with open('df_with_embeddings.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "# Zielvariable (Label) und Features definieren\n",
    "X = df['Embeddings'].tolist()  # Die BERT-Embeddings als Features\n",
    "y = df['NegoOutcomeLabel']     # Die Zielvariable für Erfolg (1) oder keinen Erfolg (0)\n",
    "\n",
    "# Train-Test-Split (noch unausgeglichen)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Konvertiere die Features (Listen) in einen 2D-Array für SMOTE\n",
    "import numpy as np\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "# SMOTE anwenden, um die Klasse 0 zu oversamplen\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Optional: Überprüfe die neue Verteilung der Klassen\n",
    "from collections import Counter\n",
    "print(\"Class distribution after SMOTE:\", Counter(y_train_resampled))\n",
    "\n",
    "# Trainiere ein Klassifikationsmodell (z. B. RandomForest)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Teste das Modell\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Ergebnisse auswerten\n",
    "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7694013303769401\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.26      0.34       104\n",
      "           1       0.81      0.92      0.86       347\n",
      "\n",
      "    accuracy                           0.77       451\n",
      "   macro avg       0.65      0.59      0.60       451\n",
      "weighted avg       0.74      0.77      0.74       451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Lade die DataFrame mit Embeddings aus der Pickle-Datei\n",
    "with open('df_with_embeddings.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "# Zielvariable und BERT-Embeddings extrahieren\n",
    "X_embeddings = df['Embeddings'].tolist()  # Die BERT-Embeddings als Features\n",
    "y = df['NegoOutcomeLabel']  # Zielvariable (1 = Erfolg, 0 = Kein Erfolg)\n",
    "\n",
    "# Feature Engineering: Zusätzliche Features aus dem Text (Content-Spalte)\n",
    "df['Length'] = df['Content'].apply(len)  # Textlänge\n",
    "df['Word count'] = df['Content'].apply(lambda x: len(x.split()))  # Wortanzahl\n",
    "\n",
    "\n",
    "# Kombiniere alle Features: BERT-Embeddings + neue Features\n",
    "X_additional = df[['Length', 'Word count'] ].values\n",
    "X_embeddings = np.array(X_embeddings)\n",
    "X_combined = np.hstack((X_embeddings, X_additional))  # Zusammenführen der Features\n",
    "\n",
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SMOTE anwenden, um den Datensatz auszugleichen\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# RandomForest-Modell trainieren\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Ergebnisse auswerten\n",
    "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
